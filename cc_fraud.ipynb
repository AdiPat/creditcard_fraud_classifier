{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "Case study for Data Mining and Business Intelligence Course.\n",
    "\n",
    "**Objectives**\n",
    "- Apply Data Mining techniques to develop smarter Fraud Detection systems.\n",
    "- Understand the effect of PCA method on choice of classification model.\n",
    "- Analyze different classifier performance metrics.\n",
    "- Preprocessing and validating performance on imbalanced data.\n",
    "- Apply sampling methods to prevent overfitting.\n",
    "\n",
    "**Observations**\n",
    "- Data is heavily unbalanced, fraudulent transactions only include 0.17% of all transactions\n",
    "- Undersampling gives astronomically better results than oversampling because the performance isn't heavily affected due to information loss as compared to large duplication of information. \n",
    "- Accuracy is not a an appropriate metric of performance for this problem, AUC and miss-ratio are better metrics to gain insight into classifier performance.\n",
    "- As features V1-V24 are generated as a result of PCA, they are weakly co-related, making Naive Bayes a good choice for the model.\n",
    "- Test if cross validation reduces false negatives i.e. classifying a fraudulent transaction as not fraud.\n",
    "- Bernoulli Naive Bayes should perform better than Gaussian Naive Bayes in practise, as it penalizes the model for incorrect classifications. However, in this data set, the effect is just marginally visible.\n",
    "\n",
    "**Tasks done**\n",
    "- Implemented random under sampling to solve the problem of overfitting due to highly unbalanced data. (0.17% of fraudulent transactions)\n",
    "- Implemented Bernoulli Naive Bayes model to classify fraudulent transactions.\n",
    "- Studied and analysed different performance metrics like precision, miss rate, F1 Score, ROC AUC and confusion matrix for gaining an intuitive evaluation of classifier performance.\n",
    "\n",
    "[Dataset - Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cc_data = pd.read_csv('data/creditcard.csv')\n",
    "\n",
    "maj_class = cc_data[cc_data.Class == 0]\n",
    "min_class = cc_data[cc_data.Class == 1]\n",
    "\n",
    "## Class distribution\n",
    "maj_class_count = maj_class.shape[0]\n",
    "min_class_count = min_class.shape[0]\n",
    "print(f\"Class distribution: {round((min_class_count/maj_class_count)*100,4)}% frauduluent transactions | minority class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "## Pre-process data\n",
    "\n",
    "## Random under sampling on majority class\n",
    "maj_class_us = maj_class.sample(n=min_class_count)\n",
    "cc_us = pd.concat([maj_class_us, min_class], axis=0)\n",
    "#cc_us = cc_data\n",
    "\n",
    "## Split training and testing data\n",
    "X = cc_us[[c for c in cc_us.columns if c != 'Class']]\n",
    "Y = cc_us['Class']\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING: Random oversampling\n",
    "# min_class_os = min_class.sample(n=492, replace=True)\n",
    "# cc_us = pd.concat([maj_class, min_class_os], axis=0)\n",
    "\n",
    "# X = cc_us[[c for c in cc_us.columns if c != 'Class']]\n",
    "# Y = cc_us['Class']\n",
    "\n",
    "# trainX, testX, trainY, testY = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,  roc_auc_score, f1_score, average_precision_score\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "pred = model.predict(testX)\n",
    "\n",
    "\n",
    "#print(confusion_matrix(pred, testY))\n",
    "\n",
    "cm = confusion_matrix(pred, testY)\n",
    "tp,tn,fp,fn = cm[0][0], cm[1][1], cm[1][0], cm[0][1]\n",
    "\n",
    "\n",
    "print(f\"TP = {tp} | FP = {fp} | TN = {tn} | FN = {fn}\")\n",
    "print(\"accuracy: \", accuracy_score(pred, testY))\n",
    "print(\"ROC AUC:\", roc_auc_score(pred, testY))\n",
    "print(\"precision: \", (tp/(tp+fp)))\n",
    "print(\"Miss rate: \", (fn/(tp+fn)))\n",
    "print(\"F1 score:\", f1_score(pred, testY))\n",
    "print(\"AP:\", average_precision_score(pred, testY))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}